import { NextRequest, NextResponse } from 'next/server';
import { generatePassage, ModelType } from '@/lib/openai';
import { generatePassagePrompt } from '@/lib/prompts';
import { PassageInput, AreaType } from '@/types';

// ì˜¤ë¥˜ ìœ í˜• ì •ì˜
enum ErrorType {
  OPENAI_API_ERROR = 'OPENAI_API_ERROR',
  DATABASE_ERROR = 'DATABASE_ERROR',
  INPUT_VALIDATION_ERROR = 'INPUT_VALIDATION_ERROR',
  GPT_RESPONSE_ERROR = 'GPT_RESPONSE_ERROR'
}

// í•œêµ­ì–´ ì˜¤ë¥˜ ë©”ì‹œì§€ ë§¤í•‘
const ERROR_MESSAGES = {
  [ErrorType.OPENAI_API_ERROR]: 'AI ì„œë¹„ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.',
  [ErrorType.DATABASE_ERROR]: 'ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.',
  [ErrorType.INPUT_VALIDATION_ERROR]: 'ì…ë ¥ëœ ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.',
  [ErrorType.GPT_RESPONSE_ERROR]: 'ì§€ë¬¸ ìƒì„± í˜•ì‹ì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.',
  UNKNOWN_ERROR: 'ì§€ë¬¸ ìƒì„± ì¤‘ ì˜ˆìƒí•˜ì§€ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
};

// HTTP ìƒíƒœ ì½”ë“œ ë§¤í•‘
const ERROR_STATUS_CODES = {
  [ErrorType.OPENAI_API_ERROR]: 503,
  [ErrorType.DATABASE_ERROR]: 500,
  [ErrorType.INPUT_VALIDATION_ERROR]: 400,
  [ErrorType.GPT_RESPONSE_ERROR]: 422
};

// ì˜¤ë¥˜ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜
function classifyError(error: any): ErrorType {
  const errorMessage = error.message?.toLowerCase() || '';
  const errorCode = error.code || error.status;

  // OpenAI API ì˜¤ë¥˜
  if (errorCode === 401 || errorCode === 429 || errorCode === 503) {
    return ErrorType.OPENAI_API_ERROR;
  }
  if (errorMessage.includes('openai') || errorMessage.includes('api key') || 
      errorMessage.includes('rate limit') || errorMessage.includes('quota')) {
    return ErrorType.OPENAI_API_ERROR;
  }

  // ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜
  if (errorMessage.includes('supabase') || errorMessage.includes('database') || 
      errorMessage.includes('connection') || errorMessage.includes('timeout')) {
    return ErrorType.DATABASE_ERROR;
  }

  // GPT ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜
  if (errorMessage.includes('json') || errorMessage.includes('parse') || 
      errorMessage.includes('invalid response') || errorMessage.includes('format')) {
    return ErrorType.GPT_RESPONSE_ERROR;
  }

  // ì…ë ¥ ê²€ì¦ ì˜¤ë¥˜ (ì´ë¯¸ ë³„ë„ ì²˜ë¦¬ë˜ì–´ ì—¬ê¸° ë„ë‹¬ ê°€ëŠ¥ì„± ë‚®ìŒ)
  if (errorMessage.includes('validation') || errorMessage.includes('required') || 
      errorMessage.includes('invalid input')) {
    return ErrorType.INPUT_VALIDATION_ERROR;
  }

  // ê¸°ë³¸ê°’
  return ErrorType.OPENAI_API_ERROR; // ëŒ€ë¶€ë¶„ AI API ê´€ë ¨ ë¬¸ì œì¼ ê°€ëŠ¥ì„± ë†’ìŒ
}

// êµ¬ì¡°í™”ëœ ì˜¤ë¥˜ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
function createErrorResponse(error: any, context: string = 'ì§€ë¬¸ ìƒì„±') {
  const errorType = classifyError(error);
  const message = ERROR_MESSAGES[errorType] || ERROR_MESSAGES.UNKNOWN_ERROR;
  const statusCode = ERROR_STATUS_CODES[errorType] || 500;

  // ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ (í”„ë¡œë•ì…˜ ì•ˆì „)
  const errorMetadata = {
    error: {
      message: error.message || String(error),
      stack: process.env.NODE_ENV === 'development' ? error.stack : undefined,
      name: error.name,
      code: error.code || error.status
    },
    errorType,
    context,
    timestamp: new Date().toISOString(),
    request: {
      userAgent: (global as any).currentRequest?.headers?.get('user-agent') || 'unknown',
      ip: (global as any).currentRequest?.headers?.get('x-forwarded-for') || 'unknown',
      method: (global as any).currentRequest?.method || 'unknown',
      url: (global as any).currentRequest?.url || 'unknown'
    },
    system: {
      nodeVersion: process.version,
      platform: process.platform,
      memory: process.memoryUsage(),
      uptime: process.uptime()
    }
  };

  console.error(`[${errorType}] ${context} ì˜¤ë¥˜:`, errorMetadata);

  return NextResponse.json(
    { 
      error: { 
        message,
        type: errorType,
        timestamp: errorMetadata.timestamp
      }
    },
    { status: statusCode }
  );
}

export async function POST(request: NextRequest) {
  try {
    const body: PassageInput & { model?: ModelType } = await request.json();
    const model = body.model || 'gpt-4.1'; // ê¸°ë³¸ê°’ gpt-4.1
    
    console.log('ğŸ“ Received body:', JSON.stringify(body, null, 2));
    console.log('ğŸ¨ textType value:', body.textType);
    console.log('ğŸ¨ textType type:', typeof body.textType);
    
    // ì…ë ¥ê°’ ê²€ì¦
    if (!body.division || !body.length || !body.subject || !body.grade || !body.area || !body.maintopic || !body.subtopic || !body.keyword) {
      return NextResponse.json(
        { error: 'ëª¨ë“  í•„ìˆ˜ í•­ëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.' },
        { status: 400 }
      );
    }

    // í”„ë¡¬í”„íŠ¸ ìƒì„± (DBì—ì„œ ì¡°íšŒ, ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)
    const { generatePassagePromptFromDB } = await import('@/lib/prompts');
    const prompt = await generatePassagePromptFromDB(
      body.division,
      body.length,
      body.subject,
      body.grade,
      body.area as AreaType, // íƒ€ì… ìºìŠ¤íŒ…
      body.maintopic,
      body.subtopic,
      body.keyword,
      body.textType,
      body.keywords_for_passages,
      body.keywords_for_questions
    );

    console.log('Generated prompt:', prompt);
    console.log('ğŸ” í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì¹˜í™˜ ìƒíƒœ í™•ì¸:');
    console.log('- keywords_for_passages:', body.keywords_for_passages);
    console.log('- keywords_for_questions:', body.keywords_for_questions);
    console.log('- ì¹˜í™˜ëœ í”„ë¡¬í”„íŠ¸ ë‚´ìš© í™•ì¸:', prompt.includes('{keywords_for_passages}') ? 'âŒ ë¯¸ì¹˜í™˜' : 'âœ… ì¹˜í™˜ì™„ë£Œ');
    console.log(`ğŸ¯ ì„ íƒëœ ëª¨ë¸: ${model}`);

    // GPT API í˜¸ì¶œ (ëª¨ë¸ íŒŒë¼ë¯¸í„° í¬í•¨)
    const result = await generatePassage(prompt, model);

    console.log('GPT response:', result);

    // ê²°ê³¼ì— ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜
    return NextResponse.json({
      ...result,
      _metadata: {
        usedPrompt: prompt,
        usedModel: model,
        generatedAt: new Date().toISOString()
      }
    });
  } catch (error) {
    return createErrorResponse(error, 'ì§€ë¬¸ ìƒì„±');
  }
}