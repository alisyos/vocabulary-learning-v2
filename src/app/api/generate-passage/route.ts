import { NextRequest, NextResponse } from 'next/server';
import { generatePassage, ModelType } from '@/lib/openai';
import { generatePassagePrompt } from '@/lib/prompts';
import { PassageInput, AreaType } from '@/types';

export async function POST(request: NextRequest) {
  try {
    const body: PassageInput & { model?: ModelType } = await request.json();
    const model = body.model || 'gpt-4.1'; // ê¸°ë³¸ê°’ gpt-4.1
    
    console.log('ğŸ“ Received body:', JSON.stringify(body, null, 2));
    console.log('ğŸ¨ textType value:', body.textType);
    console.log('ğŸ¨ textType type:', typeof body.textType);
    
    // ì…ë ¥ê°’ ê²€ì¦
    if (!body.division || !body.length || !body.subject || !body.grade || !body.area || !body.maintopic || !body.subtopic || !body.keyword) {
      return NextResponse.json(
        { error: 'ëª¨ë“  í•„ìˆ˜ í•­ëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.' },
        { status: 400 }
      );
    }

    // í”„ë¡¬í”„íŠ¸ ìƒì„± (DBì—ì„œ ì¡°íšŒ, ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)
    const { generatePassagePromptFromDB } = await import('@/lib/prompts');
    const prompt = await generatePassagePromptFromDB(
      body.division,
      body.length,
      body.subject,
      body.grade,
      body.area as AreaType, // íƒ€ì… ìºìŠ¤íŒ…
      body.maintopic,
      body.subtopic,
      body.keyword,
      body.textType
    );

    console.log('Generated prompt:', prompt);
    console.log(`ğŸ¯ ì„ íƒëœ ëª¨ë¸: ${model}`);

    // GPT API í˜¸ì¶œ (ëª¨ë¸ íŒŒë¼ë¯¸í„° í¬í•¨)
    const result = await generatePassage(prompt, model);

    console.log('GPT response:', result);

    // ê²°ê³¼ì— ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ì™€ ëª¨ë¸ ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜
    return NextResponse.json({
      ...result,
      _metadata: {
        usedPrompt: prompt,
        usedModel: model,
        generatedAt: new Date().toISOString()
      }
    });
  } catch (error) {
    console.error('Error generating passage:', error);
    return NextResponse.json(
      { error: 'ì§€ë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    );
  }
}