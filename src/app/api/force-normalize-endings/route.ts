import { NextResponse } from 'next/server';
import { supabase } from '@/lib/supabase';
import { normalizeEndingSentence } from '@/lib/textUtils';

/**
 * ì¢…ê²° ì–´ë¯¸ ê°•ì œ ì¬ì •ê·œí™” API
 *
 * POST /api/force-normalize-endings
 *
 * ë³€ê²½ ì—¬ë¶€ì™€ ìƒê´€ì—†ì´ ëª¨ë“  ë°ì´í„°ë¥¼ ì¬ì •ê·œí™”í•©ë‹ˆë‹¤.
 * - ì´ë¯¸ ì •ê·œí™”ëœ ë°ì´í„°ë„ ë‹¤ì‹œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
 * - ìµœì‹  normalizeEndingSentence í•¨ìˆ˜ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
 */
export async function POST(request: Request) {
  try {
    console.log('ğŸš€ ì¢…ê²° ì–´ë¯¸ ê°•ì œ ì¬ì •ê·œí™” ì‹œì‘');

    const stats = {
      vocabularyQuestions: { total: 0, updated: 0, errors: 0 },
      paragraphQuestions: { total: 0, updated: 0, errors: 0 },
      comprehensiveQuestions: { total: 0, updated: 0, errors: 0 },
    };

    // ========================================
    // 1. ì–´íœ˜ ë¬¸ì œ ê°•ì œ ì—…ë°ì´íŠ¸
    // ========================================
    console.log('ğŸ“š ì–´íœ˜ ë¬¸ì œ ê°•ì œ ì •ê·œí™” ì‹œì‘...');

    const { data: vocabQuestions, error: vocabFetchError } = await supabase
      .from('vocabulary_questions')
      .select('*');

    if (vocabFetchError) throw vocabFetchError;

    if (vocabQuestions) {
      stats.vocabularyQuestions.total = vocabQuestions.length;

      for (const question of vocabQuestions) {
        try {
          const updates: any = {
            question_text: normalizeEndingSentence(question.question_text),
            explanation: normalizeEndingSentence(question.explanation),
          };

          // ë³´ê¸° 1~5 ê°•ì œ ì •ê·œí™”
          [1, 2, 3, 4, 5].forEach(i => {
            const optionKey = `option_${i}`;
            const optionValue = question[optionKey];
            if (optionValue) {
              updates[optionKey] = normalizeEndingSentence(optionValue);
            }
          });

          const { error: updateError } = await supabase
            .from('vocabulary_questions')
            .update(updates)
            .eq('id', question.id);

          if (updateError) {
            console.error(`âŒ ì–´íœ˜ ë¬¸ì œ ${question.id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:`, updateError);
            stats.vocabularyQuestions.errors++;
          } else {
            stats.vocabularyQuestions.updated++;
          }
        } catch (error) {
          console.error(`âŒ ì–´íœ˜ ë¬¸ì œ ${question.id} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
          stats.vocabularyQuestions.errors++;
        }
      }
    }

    console.log(`âœ… ì–´íœ˜ ë¬¸ì œ ì™„ë£Œ: ${stats.vocabularyQuestions.updated}/${stats.vocabularyQuestions.total} ì—…ë°ì´íŠ¸`);

    // ========================================
    // 2. ë¬¸ë‹¨ ë¬¸ì œ ê°•ì œ ì—…ë°ì´íŠ¸
    // ========================================
    console.log('ğŸ“„ ë¬¸ë‹¨ ë¬¸ì œ ê°•ì œ ì •ê·œí™” ì‹œì‘...');

    const { data: paragraphQuestions, error: paragraphFetchError } = await supabase
      .from('paragraph_questions')
      .select('*');

    if (paragraphFetchError) throw paragraphFetchError;

    if (paragraphQuestions) {
      stats.paragraphQuestions.total = paragraphQuestions.length;

      for (const question of paragraphQuestions) {
        try {
          const updates: any = {
            question_text: normalizeEndingSentence(question.question_text),
            explanation: normalizeEndingSentence(question.explanation),
          };

          // ë³´ê¸° 1~5 ê°•ì œ ì •ê·œí™”
          [1, 2, 3, 4, 5].forEach(i => {
            const optionKey = `option_${i}`;
            const optionValue = question[optionKey];
            if (optionValue) {
              updates[optionKey] = normalizeEndingSentence(optionValue);
            }
          });

          const { error: updateError } = await supabase
            .from('paragraph_questions')
            .update(updates)
            .eq('id', question.id);

          if (updateError) {
            console.error(`âŒ ë¬¸ë‹¨ ë¬¸ì œ ${question.id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:`, updateError);
            stats.paragraphQuestions.errors++;
          } else {
            stats.paragraphQuestions.updated++;
          }
        } catch (error) {
          console.error(`âŒ ë¬¸ë‹¨ ë¬¸ì œ ${question.id} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
          stats.paragraphQuestions.errors++;
        }
      }
    }

    console.log(`âœ… ë¬¸ë‹¨ ë¬¸ì œ ì™„ë£Œ: ${stats.paragraphQuestions.updated}/${stats.paragraphQuestions.total} ì—…ë°ì´íŠ¸`);

    // ========================================
    // 3. ì¢…í•© ë¬¸ì œ ê°•ì œ ì—…ë°ì´íŠ¸
    // ========================================
    console.log('ğŸ§  ì¢…í•© ë¬¸ì œ ê°•ì œ ì •ê·œí™” ì‹œì‘...');

    const { data: comprehensiveQuestions, error: comprehensiveFetchError } = await supabase
      .from('comprehensive_questions')
      .select('*');

    if (comprehensiveFetchError) throw comprehensiveFetchError;

    if (comprehensiveQuestions) {
      stats.comprehensiveQuestions.total = comprehensiveQuestions.length;

      for (const question of comprehensiveQuestions) {
        try {
          const updates: any = {
            question_text: normalizeEndingSentence(question.question_text),
            explanation: normalizeEndingSentence(question.explanation),
          };

          // ë³´ê¸° 1~5 ê°•ì œ ì •ê·œí™”
          [1, 2, 3, 4, 5].forEach(i => {
            const optionKey = `option_${i}`;
            const optionValue = question[optionKey];
            if (optionValue) {
              updates[optionKey] = normalizeEndingSentence(optionValue);
            }
          });

          const { error: updateError } = await supabase
            .from('comprehensive_questions')
            .update(updates)
            .eq('id', question.id);

          if (updateError) {
            console.error(`âŒ ì¢…í•© ë¬¸ì œ ${question.id} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨:`, updateError);
            stats.comprehensiveQuestions.errors++;
          } else {
            stats.comprehensiveQuestions.updated++;
          }
        } catch (error) {
          console.error(`âŒ ì¢…í•© ë¬¸ì œ ${question.id} ì²˜ë¦¬ ì‹¤íŒ¨:`, error);
          stats.comprehensiveQuestions.errors++;
        }
      }
    }

    console.log(`âœ… ì¢…í•© ë¬¸ì œ ì™„ë£Œ: ${stats.comprehensiveQuestions.updated}/${stats.comprehensiveQuestions.total} ì—…ë°ì´íŠ¸`);

    // ========================================
    // ìµœì¢… ê²°ê³¼ ë°˜í™˜
    // ========================================
    const totalUpdated =
      stats.vocabularyQuestions.updated +
      stats.paragraphQuestions.updated +
      stats.comprehensiveQuestions.updated;

    const totalErrors =
      stats.vocabularyQuestions.errors +
      stats.paragraphQuestions.errors +
      stats.comprehensiveQuestions.errors;

    console.log('ğŸ‰ ê°•ì œ ì¬ì •ê·œí™” ì™„ë£Œ!');
    console.log(`   - ì´ ì—…ë°ì´íŠ¸: ${totalUpdated}ê°œ`);
    console.log(`   - ì´ ì˜¤ë¥˜: ${totalErrors}ê°œ`);

    return NextResponse.json({
      success: totalErrors === 0,
      message: `ê°•ì œ ì¬ì •ê·œí™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. (${totalUpdated}ê°œ ì—…ë°ì´íŠ¸, ${totalErrors}ê°œ ì˜¤ë¥˜)`,
      stats,
      summary: {
        totalUpdated,
        totalErrors,
        totalProcessed:
          stats.vocabularyQuestions.total +
          stats.paragraphQuestions.total +
          stats.comprehensiveQuestions.total
      }
    });

  } catch (error) {
    console.error('âŒ ê°•ì œ ì¬ì •ê·œí™” ì‹¤íŒ¨:', error);
    return NextResponse.json(
      {
        success: false,
        message: 'ê°•ì œ ì¬ì •ê·œí™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
        error: error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
      },
      { status: 500 }
    );
  }
}
