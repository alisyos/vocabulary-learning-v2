import OpenAI from 'openai';

// OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ì§€ì›í•˜ëŠ” ëª¨ë¸ íƒ€ì…
export type ModelType = 'gpt-4.1' | 'gpt-5';

// ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ íƒ€ì…
export interface StreamingResponse {
  content: string;
  isComplete: boolean;
  error?: string;
}

// GPT API í˜¸ì¶œ í•¨ìˆ˜ (ëª¨ë¸ ì„ íƒ ê°€ëŠ¥)
export async function callGPT(prompt: string, maxTokens: number = 2000, model: ModelType = 'gpt-4.1') {
  console.log(`ğŸ¤– OpenAI API í˜¸ì¶œ - ëª¨ë¸: ${model}, maxTokens: ${maxTokens}`);
  
  try {
    const systemPrompt = 'ë‹¹ì‹ ì€ êµìœ¡ ì½˜í…ì¸  ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.';
    
    let content: string | null = null;
    
    if (model === 'gpt-5') {
      console.log('ğŸš€ GPT-5 API ì‚¬ìš© (responses.create)');
      // GPT-5 ìƒˆë¡œìš´ API í˜•ì‹ ì‚¬ìš©
      const fullInput = `${systemPrompt}\n\n${prompt}`;
      
      const response = await client.responses.create({
        model: 'gpt-5',
        input: fullInput,
      });
      
      content = response.output_text;
    } else {
      console.log('ğŸ“Œ GPT-4.1 API ì‚¬ìš© (chat.completions.create)');
      // GPT-4.1 ê¸°ì¡´ API í˜•ì‹ ì‚¬ìš©
      const response = await client.chat.completions.create({
        model: 'gpt-4.1',
        messages: [
          {
            role: 'system',
            content: systemPrompt,
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        max_tokens: maxTokens,
        temperature: 0.7,
      });
      
      content = response.choices[0]?.message?.content || null;
    }
    
    if (!content) {
      throw new Error('No content received from OpenAI');
    }

    // JSON íŒŒì‹± ì‹œë„
    try {
      return JSON.parse(content);
    } catch (parseError) {
      // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
      console.warn('Failed to parse JSON response:', parseError);
      return { raw: content };
    }
  } catch (error) {
    console.error(`Error calling OpenAI API with model ${model}:`, error);
    throw error;
  }
}

// ìŠ¤íŠ¸ë¦¬ë° GPT API í˜¸ì¶œ í•¨ìˆ˜
export async function* callGPTStream(prompt: string, maxTokens: number = 2000, model: ModelType = 'gpt-4.1'): AsyncGenerator<StreamingResponse, void, unknown> {
  console.log(`ğŸš€ OpenAI ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ - ëª¨ë¸: ${model}, maxTokens: ${maxTokens}`);
  
  try {
    const systemPrompt = 'ë‹¹ì‹ ì€ êµìœ¡ ì½˜í…ì¸  ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.';
    
    let stream;
    
    if (model === 'gpt-5') {
      console.log('ğŸš€ GPT-5 ìŠ¤íŠ¸ë¦¬ë° API ì‚¬ìš©');
      // GPT-5ì˜ ê²½ìš° ì¼ë°˜ ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬ (ìŠ¤íŠ¸ë¦¬ë° ë¯¸ì§€ì› ê°€ì •)
      const fullInput = `${systemPrompt}\n\n${prompt}`;
      const response = await client.responses.create({
        model: 'gpt-5',
        input: fullInput,
      });
      
      yield {
        content: response.output_text || '',
        isComplete: true
      };
      return;
    } else {
      console.log('ğŸ“¡ GPT-4.1 ìŠ¤íŠ¸ë¦¬ë° API ì‚¬ìš©');
      // GPT-4.1 ìŠ¤íŠ¸ë¦¬ë° API ì‚¬ìš©
      stream = await client.chat.completions.create({
        model: 'gpt-4.1',
        messages: [
          {
            role: 'system',
            content: systemPrompt,
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        max_tokens: maxTokens,
        temperature: 0.7,
        stream: true, // ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
      });
    }
    
    let fullContent = '';
    
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || '';
      
      if (content) {
        fullContent += content;
        
        yield {
          content: fullContent,
          isComplete: false
        };
      }
      
      // ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ ì²´í¬
      if (chunk.choices[0]?.finish_reason) {
        yield {
          content: fullContent,
          isComplete: true
        };
        break;
      }
    }
    
  } catch (error) {
    console.error(`Error calling OpenAI streaming API with model ${model}:`, error);
    yield {
      content: '',
      isComplete: true,
      error: error instanceof Error ? error.message : String(error)
    };
  }
}

// ì§€ë¬¸ ìƒì„± ì „ìš© í•¨ìˆ˜
export async function generatePassage(prompt: string, model: ModelType = 'gpt-4.1') {
  return await callGPT(prompt, 10000, model);
}

// ì§€ë¬¸ ìƒì„± ìŠ¤íŠ¸ë¦¬ë° ì „ìš© í•¨ìˆ˜
export async function* generatePassageStream(prompt: string, model: ModelType = 'gpt-4.1'): AsyncGenerator<StreamingResponse, void, unknown> {
  yield* callGPTStream(prompt, 10000, model);
}

// ë¬¸ì œ ìƒì„± ì „ìš© í•¨ìˆ˜
export async function generateQuestion(prompt: string, model: ModelType = 'gpt-4.1') {
  return await callGPT(prompt, 10000, model);
}